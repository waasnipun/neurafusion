{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cb51636c35ff179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.066661Z",
     "start_time": "2023-12-08T20:49:30.193666Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mini_imagenet_dataset import MiniImageNetDataset\n",
    "from tools import getDataset, print_class_distribution\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0c1117e99dc7cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.131235Z",
     "start_time": "2023-12-08T20:49:31.127636Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca9bdb650d1ebe5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.684904Z",
     "start_time": "2023-12-08T20:49:31.553813Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 4\n",
    "learning_rate = 0.0001 # 0.00005 - the best one so far\n",
    "num_epochs = 10\n",
    "image_size = 84\n",
    "num_classes = 50\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), 'datasets/miniImageNet')\n",
    "dataset, label_mapping = getDataset(path=root_dir, num_classes=num_classes)\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomCrop(84, padding=8),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "            transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomCrop(84, padding=8),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "       \n",
    "train_dataset, temp_dataset = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "val_dataset, test_dataset = train_test_split(temp_dataset, test_size=0.5, random_state=42)\n",
    "      \n",
    "train_dataset = MiniImageNetDataset(dataset=train_dataset, path=root_dir, phase='train', transform=train_transforms)\n",
    "val_dataset = MiniImageNetDataset(dataset=val_dataset, path=root_dir, phase='val', transform=transforms)\n",
    "test_dataset = MiniImageNetDataset(dataset=test_dataset, path=root_dir, phase='test', transform=transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfab17de52b40940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.696316Z",
     "start_time": "2023-12-08T20:49:31.691779Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval(net, data_loader, criterion=nn.CrossEntropyLoss()):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "    net.eval()\n",
    "    correct = 0.0\n",
    "    num_images = 0.0\n",
    "    loss = 0.0\n",
    "    for i_batch, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outs = net(images)\n",
    "        loss += criterion(outs, labels).item()\n",
    "        _, predicted = torch.max(outs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        num_images += len(labels)\n",
    "        print('testing/evaluating -> batch: %d correct: %d numb images: %d' % (i_batch, correct, num_images) + '\\r', end='')\n",
    "    acc = correct / num_images\n",
    "    loss /= len(data_loader)\n",
    "    return acc, loss\n",
    "\n",
    "\n",
    "# training function\n",
    "def train(net, train_loader, valid_loader):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(params= net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.0001, betas=(0.5, 0.999))\n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    training_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        correct = 0.0  # used to accumulate number of correctly recognized images\n",
    "        num_images = 0.0  # used to accumulate number of images\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i_batch, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output_train = net(images)\n",
    "            loss = criterion(output_train, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicts = output_train.argmax(dim=1)\n",
    "            correct += predicts.eq(labels).sum().item()\n",
    "            num_images += len(labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            print('training -> epoch: %d, batch: %d, loss: %f' % (epoch, i_batch, loss.item()) + '\\r', end='')\n",
    "\n",
    "        print()\n",
    "        acc = correct / num_images\n",
    "        acc_eval, val_loss = eval(net, valid_loader)\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        training_losses.append(average_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print('\\nepoch: %d, lr: %f, accuracy: %f, avg. loss: %f, valid accuracy: %f valid loss: %f\\n' % (epoch, optimizer.param_groups[0]['lr'], acc, average_loss, acc_eval, val_loss))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return net, training_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1111f6cab32449a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T00:53:51.862621Z",
     "start_time": "2023-12-08T00:28:18.503060Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "Batch Size: 128\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 10\n",
      "Number of Workers: 4\n",
      "Number of Classes: 50\n",
      "\n",
      "training -> epoch: 0, batch: 160, loss: 1.336646\n",
      "testing/evaluating -> batch: 34 correct: 2986 numb images: 4410\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.472935, avg. loss: 2.110046, valid accuracy: 0.677098 valid loss: 1.202568\n",
      "\n",
      "training -> epoch: 1, batch: 160, loss: 1.153150\n",
      "testing/evaluating -> batch: 34 correct: 3249 numb images: 4410\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.689504, avg. loss: 1.118639, valid accuracy: 0.736735 valid loss: 0.966275\n",
      "\n",
      "training -> epoch: 2, batch: 160, loss: 1.002141\n",
      "testing/evaluating -> batch: 34 correct: 3305 numb images: 4410\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.748639, avg. loss: 0.880443, valid accuracy: 0.749433 valid loss: 0.905919\n",
      "\n",
      "training -> epoch: 3, batch: 160, loss: 0.695493\n",
      "testing/evaluating -> batch: 34 correct: 3280 numb images: 4410\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.789553, avg. loss: 0.733809, valid accuracy: 0.743764 valid loss: 0.899790\n",
      "\n",
      "training -> epoch: 4, batch: 160, loss: 0.665388\n",
      "testing/evaluating -> batch: 34 correct: 3338 numb images: 4410\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.822643, avg. loss: 0.617407, valid accuracy: 0.756916 valid loss: 0.866900\n",
      "\n",
      "training -> epoch: 5, batch: 160, loss: 0.570206\n",
      "testing/evaluating -> batch: 34 correct: 3341 numb images: 4410\n",
      "epoch: 5, lr: 0.000100, accuracy: 0.850680, avg. loss: 0.514247, valid accuracy: 0.757596 valid loss: 0.862082\n",
      "\n",
      "training -> epoch: 6, batch: 160, loss: 0.521158\n",
      "testing/evaluating -> batch: 34 correct: 3365 numb images: 4410\r"
     ]
    }
   ],
   "source": [
    "from models.resnet18 import ResNet18\n",
    "\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Number of Workers: {num_workers}\")\n",
    "print(f\"Number of Classes: {num_classes}\\n\")\n",
    "\n",
    "# print_class_distribution(train_dataset, \"Training\", label_mapping)\n",
    "# print_class_distribution(val_dataset, \"Validation\", label_mapping)\n",
    "# print_class_distribution(test_dataset, \"Testing\", label_mapping)\n",
    "\n",
    "model = ResNet18(num_classes=num_classes).to(device)\n",
    "model, training_losses, val_losses = train(net=model, train_loader=train_loader, valid_loader=validation_loader)\n",
    "\n",
    "acc_test, test_loss = eval(model, test_loader)\n",
    "print('\\naccuracy on testing data: %f' % acc_test)\n",
    "\n",
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190876f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, os.path.join(os.getcwd(), 'pretrained/resnet18_model_75.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6f8e94e82f5e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T00:59:27.037819Z",
     "start_time": "2023-12-08T00:59:16.296902Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([47, 11, 23, 10,  9,  3,  3, 30, 27, 48, 25, 23, 16, 10, 23, 39, 20, 10,\n",
      "        31, 22, 18, 17, 25, 17, 19, 30, 42,  1, 30, 43, 45, 38, 45, 27, 25,  7,\n",
      "         3, 21,  6, 48, 29, 47, 19, 16, 37, 29, 34, 24, 39,  0, 46, 43, 15, 30,\n",
      "        36, 46, 31, 25, 32,  3,  6, 37, 16, 31,  5, 10, 41, 30, 21,  1, 35, 33,\n",
      "        29, 27, 47, 23, 25, 12, 39,  8, 10, 19,  0, 39, 40, 13, 13, 20, 41, 22,\n",
      "        25, 34, 46, 38, 33,  1, 16,  1, 38, 17, 17, 22,  1, 16, 13, 10,  9, 15,\n",
      "        31, 29, 31, 12, 27, 16,  3, 12, 30, 11, 12, 40, 22, 16, 42, 22, 30,  5,\n",
      "        18,  6], device='mps:0')\n",
      "tensor([47, 11, 23, 10,  9, 12,  3, 30, 27, 48, 25, 23, 16, 10, 23, 28, 20, 10,\n",
      "        31,  2, 34, 17, 25, 17, 19, 30, 42, 15, 30, 28, 11, 28, 45, 27, 25,  7,\n",
      "         3, 21, 22, 34, 29, 47, 19, 16, 37,  7, 34, 24, 39, 47, 46, 43, 10, 30,\n",
      "        32, 46, 31, 25, 32, 47,  6, 37, 39, 31,  5, 44, 41, 30, 22,  1, 35, 33,\n",
      "        29, 27, 47, 23, 19, 36, 39,  8, 10, 19, 32, 44, 40, 13, 13, 28, 41, 22,\n",
      "        25,  8, 46, 38, 33, 15, 16,  1, 38, 17, 17, 16, 18, 16, 13, 10,  9, 45,\n",
      "        31, 29, 31, 12, 27, 16,  3, 12, 30, 35, 12, 40, 22, 16, 42, 44, 30,  5,\n",
      "        18,  6], device='mps:0')\n",
      "98 128\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "\n",
    "for i_batch, (images, labels) in enumerate(test_loader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outs = model(images)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    print(predicted)\n",
    "    print(labels)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    print(correct, len(labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2fc501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046875"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "103/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43452f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
