{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cb51636c35ff179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.066661Z",
     "start_time": "2023-12-08T20:49:30.193666Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import Dataset\n",
    "from tools import getDataset, print_class_distribution\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0c1117e99dc7cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.131235Z",
     "start_time": "2023-12-08T20:49:31.127636Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca9bdb650d1ebe5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.684904Z",
     "start_time": "2023-12-08T20:49:31.553813Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 4\n",
    "learning_rate = 0.0001 \n",
    "num_epochs = 15\n",
    "image_size = 84\n",
    "num_classes = 50\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), 'datasets/miniImageNet')\n",
    "dataset, label_mapping = getDataset(path=root_dir, num_classes=num_classes)\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomCrop(84, padding=8),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "            transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.3891, 0.3891, 0.3891), (0.2877, 0.2877, 0.2877)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomCrop(84, padding=8),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.3891, 0.3891, 0.3891), (0.2877, 0.2877, 0.2877)),\n",
    "        ]\n",
    "    )\n",
    "       \n",
    "train_dataset, temp_dataset = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "val_dataset, test_dataset = train_test_split(temp_dataset, test_size=0.5, random_state=42)\n",
    "      \n",
    "train_dataset = Dataset(dataset=train_dataset, path=root_dir, phase='train', transform=train_transforms)\n",
    "val_dataset = Dataset(dataset=val_dataset, path=root_dir, phase='val', transform=transforms)\n",
    "test_dataset = Dataset(dataset=test_dataset, path=root_dir, phase='test', transform=transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfab17de52b40940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.696316Z",
     "start_time": "2023-12-08T20:49:31.691779Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval(net, data_loader, criterion=nn.CrossEntropyLoss()):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "    net.eval()\n",
    "    correct = 0.0\n",
    "    num_images = 0.0\n",
    "    loss = 0.0\n",
    "    for i_batch, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outs = net(images)\n",
    "        loss += criterion(outs, labels).item()\n",
    "        _, predicted = torch.max(outs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        num_images += len(labels)\n",
    "        print('testing/evaluating -> batch: %d correct: %d numb images: %d' % (i_batch, correct, num_images) + '\\r', end='')\n",
    "    acc = correct / num_images\n",
    "    loss /= len(data_loader)\n",
    "    return acc, loss\n",
    "\n",
    "\n",
    "# training function\n",
    "def train(net, train_loader, valid_loader):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(params= net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.0001, betas=(0.5, 0.999))\n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.01)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    training_losses = []\n",
    "    training_losses_epoch = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        correct = 0.0  # used to accumulate number of correctly recognized images\n",
    "        num_images = 0.0  # used to accumulate number of images\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i_batch, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output_train = net(images)\n",
    "            loss = criterion(output_train, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicts = output_train.argmax(dim=1)\n",
    "            correct += predicts.eq(labels).sum().item()\n",
    "            num_images += len(labels)\n",
    "            total_loss += loss.item()\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            print('training -> epoch: %d, batch: %d, loss: %f' % (epoch, i_batch, loss.item()) + '\\r', end='')\n",
    "\n",
    "        print()\n",
    "        acc = correct / num_images\n",
    "        acc_eval, val_loss = eval(net, valid_loader)\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        training_losses_epoch.append(average_loss)\n",
    "        print('\\nepoch: %d, lr: %f, accuracy: %f, avg. loss: %f, valid accuracy: %f valid loss: %f\\n' % (epoch, optimizer.param_groups[0]['lr'], acc, average_loss, acc_eval, val_loss))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return net, training_losses, training_losses_epoch,val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1111f6cab32449a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T00:53:51.862621Z",
     "start_time": "2023-12-08T00:28:18.503060Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "Batch Size: 128\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 15\n",
      "Number of Workers: 4\n",
      "Number of Classes: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.resnet18 import ResNet18\n",
    "\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Number of Workers: {num_workers}\")\n",
    "print(f\"Number of Classes: {num_classes}\\n\")\n",
    "\n",
    "# print_class_distribution(train_dataset, \"Training\", label_mapping)\n",
    "# print_class_distribution(val_dataset, \"Validation\", label_mapping)\n",
    "# print_class_distribution(test_dataset, \"Testing\", label_mapping)\n",
    "\n",
    "model = ResNet18(num_classes=num_classes).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "model, training_losses, training_losses_epoch, val_losses = train(net=model, train_loader=train_loader, valid_loader=validation_loader)\n",
    "\n",
    "acc_test, test_loss = eval(model, test_loader)\n",
    "print('\\naccuracy on testing data: %f' % acc_test)\n",
    "\n",
    "plt.plot(training_losses_epoch, label='Training Loss per epoch')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190876f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(os.getcwd(), f'pretrained/resnet_model_best_{round(acc_test*100, 2)}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6f8e94e82f5e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T00:59:27.037819Z",
     "start_time": "2023-12-08T00:59:16.296902Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16, 33, 31,  6, 42,  2, 15, 15, 48, 44, 19, 49, 39,  5, 33, 16,  7, 41,\n",
      "         6, 34, 19, 42,  6, 26, 25, 11, 45, 43, 28, 28, 46, 41, 14, 49, 45, 43,\n",
      "        23, 35, 30, 37, 16, 25, 39,  7, 37, 45, 43, 40,  8, 37, 30, 33, 27, 20,\n",
      "        42, 49, 19,  2, 11, 29, 25, 10, 31, 29, 23, 18, 21, 21, 33, 37, 44, 15,\n",
      "        15, 38, 16, 38, 24, 21,  9, 13, 24, 21, 27, 26,  8, 25, 38, 24, 21, 26,\n",
      "        27, 49, 36, 41, 21, 14, 42,  0,  3,  1, 21, 34, 21, 33, 34,  3, 43, 27,\n",
      "        19,  5, 31, 37, 36, 34, 16, 28, 11, 10, 20, 44,  5, 29, 42,  9, 33,  4,\n",
      "        41, 46], device='mps:0')\n",
      "tensor([16, 33, 15, 16, 42,  2, 26, 15,  6, 44, 19, 49, 39,  5, 26, 16, 33,  1,\n",
      "         6, 34,  4, 42,  6, 26, 42, 40,  5, 43, 28, 28, 46, 41, 14, 49, 45, 43,\n",
      "        23, 35, 30, 37, 44, 25, 39,  7, 37, 45, 43, 19,  8, 37, 30, 26, 27, 20,\n",
      "        42, 49, 19,  2, 17, 29, 25, 22, 17, 29, 23, 18, 21, 21, 33, 37, 29, 15,\n",
      "        15, 38, 33, 38, 24, 21, 30, 13, 24, 21, 27, 26,  8, 25, 38, 24, 21, 26,\n",
      "        27, 49, 36, 41, 21, 14, 42,  0, 18,  7, 21, 34, 21, 33, 23,  4, 43, 27,\n",
      "        19,  5, 31, 35, 16, 34, 16, 28, 23, 10, 20, 44,  5, 27, 42, 14, 33,  4,\n",
      "        41, 46], device='mps:0')\n",
      "99 128\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "\n",
    "for i_batch, (images, labels) in enumerate(test_loader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outs = model(images)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    print(predicted)\n",
    "    print(labels)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    print(correct, len(labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2fc501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "104/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43452f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
