{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb51636c35ff179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.066661Z",
     "start_time": "2023-12-08T20:49:30.193666Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import Dataset\n",
    "from tools import getDataset, print_class_distribution\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c1117e99dc7cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.131235Z",
     "start_time": "2023-12-08T20:49:31.127636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9bdb650d1ebe5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.684904Z",
     "start_time": "2023-12-08T20:49:31.553813Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 4\n",
    "learning_rate = 0.0001 # 0.00005 - the best one so far\n",
    "num_epochs = 10\n",
    "image_size = 224\n",
    "num_classes = 50\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), 'datasets/miniImageNet')\n",
    "dataset, label_mapping = getDataset(path=root_dir, num_classes=num_classes)\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "            transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "       \n",
    "train_dataset, temp_dataset = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "val_dataset, test_dataset = train_test_split(temp_dataset, test_size=0.5, random_state=42)\n",
    "      \n",
    "train_dataset = Dataset(dataset=train_dataset, path=root_dir, phase='train', transform=train_transforms)\n",
    "val_dataset = Dataset(dataset=val_dataset, path=root_dir, phase='val', transform=transforms)\n",
    "test_dataset = Dataset(dataset=test_dataset, path=root_dir, phase='test', transform=transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfab17de52b40940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.696316Z",
     "start_time": "2023-12-08T20:49:31.691779Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval(net, data_loader, criterion=nn.CrossEntropyLoss()):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "    net.eval()\n",
    "    correct = 0.0\n",
    "    num_images = 0.0\n",
    "    loss = 0.0\n",
    "    for i_batch, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outs = net(images)\n",
    "        loss += criterion(outs, labels).item()\n",
    "        _, predicted = torch.max(outs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        num_images += len(labels)\n",
    "        print('testing/evaluating -> batch: %d correct: %d numb images: %d' % (i_batch, correct, num_images) + '\\r', end='')\n",
    "    acc = correct / num_images\n",
    "    loss /= len(data_loader)\n",
    "    return acc, loss\n",
    "\n",
    "\n",
    "# training function\n",
    "def train(net, train_loader, valid_loader):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.0001, betas=(0.5, 0.999))\n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.01)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    training_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        correct = 0.0  # used to accumulate number of correctly recognized images\n",
    "        num_images = 0.0  # used to accumulate number of images\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i_batch, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output_train = net(images)\n",
    "            loss = criterion(output_train, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicts = output_train.argmax(dim=1)\n",
    "            correct += predicts.eq(labels).sum().item()\n",
    "            num_images += len(labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            print('training -> epoch: %d, batch: %d, loss: %f' % (epoch, i_batch, loss.item()) + '\\r', end='')\n",
    "\n",
    "        print()\n",
    "        acc = correct / num_images\n",
    "        acc_eval, val_loss = eval(net, valid_loader)\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        training_losses.append(average_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print('\\nepoch: %d, lr: %f, accuracy: %f, loss: %f, valid accuracy: %f\\n' % (epoch, optimizer.param_groups[0]['lr'], acc, average_loss, acc_eval))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return net, training_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100a47afbca7d92e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-07T23:48:59.323580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "Batch Size: 128\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 10\n",
      "Number of Workers: 4\n",
      "\n",
      "training -> epoch: 0, batch: 164, loss: 1.362855\n",
      "testing/evaluating -> batch: 35 correct: 1302 numb images: 4500\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.570190, loss: 1.617803, valid accuracy: 0.289333\n",
      "\n",
      "training -> epoch: 1, batch: 164, loss: 1.049437\n",
      "testing/evaluating -> batch: 35 correct: 1603 numb images: 4500\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.675286, loss: 1.211025, valid accuracy: 0.356222\n",
      "\n",
      "training -> epoch: 2, batch: 20, loss: 0.588703\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21328\\1247508125.py\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0macc_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21328\\2720868816.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, train_loader, valid_loader)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mpredicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mnum_images\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from models.VGG import VGG\n",
    "\n",
    "\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Number of Workers: {num_workers}\\n\")\n",
    "\n",
    "# print_class_distribution(train_dataset, \"Training\", label_mapping)\n",
    "# print_class_distribution(val_dataset, \"Validation\", label_mapping)\n",
    "# print_class_distribution(test_dataset, \"Testing\", label_mapping)\n",
    "\n",
    "model = VGG(num_classes=num_classes).to(device)\n",
    "model, training_losses, val_losses = train(net=model, train_loader=train_loader, valid_loader=validation_loader)\n",
    "\n",
    "acc_test, test_loss = eval(model, test_loader)\n",
    "print('\\naccuracy on testing data: %f' % acc_test)\n",
    "\n",
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "torch.save(model, os.path.join(os.getcwd(), 'pretrained/vgg_model_full_12_20.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea4a865692f9c48",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T16:10:09.511634Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model.eval()  \n",
    "\n",
    "for i_batch, (images, labels) in enumerate(test_loader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outs = model(images)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    print(predicted)\n",
    "    print(labels)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    print(correct, len(labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b04fba26407c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
