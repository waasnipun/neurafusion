{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import Dataset\n",
    "from tools import getDataset, print_class_distribution\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_loaders(num_classes, batch_size, num_workers):\n",
    "    root_dir = os.path.join(os.getcwd(), 'datasets/EuroSAT_RGB')\n",
    "    dataset, label_mapping = getDataset(path=root_dir, num_classes=num_classes, num_images_per_class=20, shuffle_images=False)\n",
    "\n",
    "    class_images = {i: [] for i in range(num_classes)}\n",
    "\n",
    "    # Group images by class\n",
    "    for image_path, class_label in dataset:\n",
    "        class_images[class_label].append((image_path, class_label))\n",
    "\n",
    "    # Initialize training and test sets\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "\n",
    "    # Select 5 images for training and 15 for testing from each class\n",
    "    for class_label, images in class_images.items():\n",
    "        train_set.extend(random.sample(images, k=5))\n",
    "        test_set.extend(list(set(images) - set(train_set)))\n",
    "\n",
    "\n",
    "    train_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomCrop(80, padding=8),\n",
    "                # transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "                # transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(degrees=5),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    test_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomCrop(80, padding=8),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    train_dataset = Dataset(dataset=train_set, path=root_dir, phase='train', transform=train_transforms)\n",
    "    test_dataset = Dataset(dataset=test_set, path=root_dir, phase='test', transform=test_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(net, data_loader, criterion=nn.CrossEntropyLoss()):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "    net.eval()\n",
    "    correct = 0.0\n",
    "    num_images = 0.0\n",
    "    loss = 0.0\n",
    "    for i_batch, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outs = net(images)\n",
    "        loss += criterion(outs, labels).item()\n",
    "        _, predicted = torch.max(outs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        num_images += len(labels)\n",
    "        print('testing -> batch: %d correct: %d num of images: %d' % (i_batch, correct, num_images) + '\\r', end='')\n",
    "    acc = correct / num_images\n",
    "    loss /= len(data_loader)\n",
    "    return acc, loss\n",
    "\n",
    "\n",
    "# training function\n",
    "def train(net, train_loader, test_loader, num_epochs, learning_rate):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(params= net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.0001, betas=(0.5, 0.999))\n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.01)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    training_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        correct = 0.0  # used to accumulate number of correctly recognized images\n",
    "        num_images = 0.0  # used to accumulate number of images\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i_batch, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output_train = net(images)\n",
    "            loss = criterion(output_train, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicts = output_train.argmax(dim=1)\n",
    "            correct += predicts.eq(labels).sum().item()\n",
    "            num_images += len(labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            print('training -> epoch: %d, batch: %d, loss: %f' % (epoch, i_batch, loss.item()) + '\\r', end='')\n",
    "\n",
    "        print()\n",
    "        acc = correct / num_images\n",
    "        acc_test, test_loss = eval(net, test_loader)\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        training_losses.append(average_loss)\n",
    "        val_losses.append(test_loss)\n",
    "        print('\\nepoch: %d, lr: %f, accuracy: %f, avg. loss: %f, test accuracy: %f test loss: %f\\n' % (epoch, optimizer.param_groups[0]['lr'], acc, average_loss, acc_test, test_loss))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return net, training_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "Batch Size: 5\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 5\n",
      "Number of Workers: 4\n",
      "Number of Classes: 5\n",
      "\n",
      "Using 20 images per class SeaLake\n",
      "Using 20 images per class HerbaceousVegetation\n",
      "Using 20 images per class Forest\n",
      "Using 20 images per class AnnualCrop\n",
      "Using 20 images per class Pasture\n",
      "training -> epoch: 0, batch: 4, loss: 4.491178\n",
      "testing -> batch: 14 correct: 3 numb images: 75\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.000000, avg. loss: 5.097606, test accuracy: 0.040000 test loss: 5.138018\n",
      "\n",
      "training -> epoch: 1, batch: 4, loss: 1.725401\n",
      "testing -> batch: 14 correct: 4 numb images: 75\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.480000, avg. loss: 2.278261, test accuracy: 0.053333 test loss: 4.556742\n",
      "\n",
      "training -> epoch: 2, batch: 4, loss: 1.223427\n",
      "testing -> batch: 14 correct: 13 numb images: 75\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.680000, avg. loss: 1.328867, test accuracy: 0.173333 test loss: 3.980239\n",
      "\n",
      "training -> epoch: 3, batch: 4, loss: 0.583495\n",
      "testing -> batch: 14 correct: 25 numb images: 75\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.680000, avg. loss: 1.168340, test accuracy: 0.333333 test loss: 3.109207\n",
      "\n",
      "training -> epoch: 4, batch: 4, loss: 3.003701\n",
      "testing -> batch: 14 correct: 30 numb images: 75\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.640000, avg. loss: 1.487092, test accuracy: 0.400000 test loss: 2.898692\n",
      "\n",
      "Using 20 images per class PermanentCrop\n",
      "Using 20 images per class River\n",
      "Using 20 images per class Highway\n",
      "Using 20 images per class AnnualCrop\n",
      "Using 20 images per class Forest\n",
      "training -> epoch: 0, batch: 4, loss: 6.945630\n",
      "testing -> batch: 14 correct: 12 numb images: 75\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.120000, avg. loss: 5.274341, test accuracy: 0.160000 test loss: 4.958868\n",
      "\n",
      "training -> epoch: 1, batch: 4, loss: 3.066837\n",
      "testing -> batch: 14 correct: 21 numb images: 75\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.360000, avg. loss: 3.145272, test accuracy: 0.280000 test loss: 3.303272\n",
      "\n",
      "training -> epoch: 2, batch: 4, loss: 0.936282\n",
      "testing -> batch: 14 correct: 31 numb images: 75\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.680000, avg. loss: 1.200565, test accuracy: 0.413333 test loss: 2.498721\n",
      "\n",
      "training -> epoch: 3, batch: 4, loss: 1.322070\n",
      "testing -> batch: 14 correct: 35 numb images: 75\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.720000, avg. loss: 0.936425, test accuracy: 0.466667 test loss: 2.289819\n",
      "\n",
      "training -> epoch: 4, batch: 4, loss: 0.297366\n",
      "testing -> batch: 14 correct: 42 numb images: 75\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.840000, avg. loss: 0.633829, test accuracy: 0.560000 test loss: 1.901891\n",
      "\n",
      "testing -> batch: 14 correct: 42 numb images: 75\r"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "num_workers = 4\n",
    "learning_rate = 0.0001 # 0.00005 - the best one so far\n",
    "num_epochs = 5\n",
    "num_classes = 5\n",
    "\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Number of Workers: {num_workers}\")\n",
    "print(f\"Number of Classes: {num_classes}\\n\")\n",
    "\n",
    "# print_class_distribution(train_dataset, \"Training\", label_mapping)\n",
    "# print_class_distribution(test_dataset, \"Testing\", label_mapping)\n",
    "\n",
    "model = torch.load(os.path.join(os.getcwd(), 'pretrained/resnet18_model_77.pth')).to(device)\n",
    "for iter in range(2):\n",
    "    train_loader, test_loader = make_dataset_loaders(num_classes=num_classes, batch_size=batch_size, num_workers=num_workers)\n",
    "    model, training_losses, val_losses = train(net=model, train_loader=train_loader, test_loader=test_loader, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n",
    "acc_test, test_loss = eval(model, test_loader)\n",
    "print('\\naccuracy on testing data: %f' % acc_test)\n",
    "\n",
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(test_loss, label='Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
