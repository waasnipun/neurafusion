{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import Dataset\n",
    "from tools import getDataset, print_class_distribution\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_loaders(num_classes, batch_size, num_workers):\n",
    "    root_dir = os.path.join(os.getcwd(), 'datasets/EuroSAT_RGB')\n",
    "    dataset, label_mapping = getDataset(path=root_dir, num_classes=num_classes, num_images_per_class=20, shuffle_images=False)\n",
    "\n",
    "    class_images = {i: [] for i in range(num_classes)}\n",
    "\n",
    "    # Group images by class\n",
    "    for image_path, class_label in dataset:\n",
    "        class_images[class_label].append((image_path, class_label))\n",
    "\n",
    "    # Initialize training and test sets\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "\n",
    "    # Select 5 images for training and 15 for testing from each class\n",
    "    for class_label, images in class_images.items():\n",
    "        train_set.extend(random.sample(images, k=5))\n",
    "        test_set.extend(list(set(images) - set(train_set)))\n",
    "\n",
    "\n",
    "    train_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomCrop(80, padding=8),\n",
    "                # transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "                # transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(degrees=5),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    test_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomCrop(80, padding=8),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    train_dataset = Dataset(dataset=train_set, path=root_dir, phase='train', transform=train_transforms)\n",
    "    test_dataset = Dataset(dataset=test_set, path=root_dir, phase='test', transform=test_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    print_class_distribution(train_dataset, \"Training\", label_mapping)\n",
    "    print_class_distribution(test_dataset, \"Testing\", label_mapping)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(net, data_loader, criterion=nn.CrossEntropyLoss()):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "    net.eval()\n",
    "    correct = 0.0\n",
    "    num_images = 0.0\n",
    "    loss = 0.0\n",
    "    for i_batch, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outs = net(images)\n",
    "        loss += criterion(outs, labels).item()\n",
    "        _, predicted = torch.max(outs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        num_images += len(labels)\n",
    "        print('testing -> batch: %d correct: %d num of images: %d' % (i_batch, correct, num_images) + '\\r', end='')\n",
    "    acc = correct / num_images\n",
    "    loss /= len(data_loader)\n",
    "    return acc, loss\n",
    "\n",
    "\n",
    "# training function\n",
    "def train(net, train_loader, test_loader, num_epochs, learning_rate):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(params= net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.0001, betas=(0.5, 0.999))\n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.01)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    training_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        correct = 0.0  # used to accumulate number of correctly recognized images\n",
    "        num_images = 0.0  # used to accumulate number of images\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i_batch, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output_train = net(images)\n",
    "            loss = criterion(output_train, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicts = output_train.argmax(dim=1)\n",
    "            correct += predicts.eq(labels).sum().item()\n",
    "            num_images += len(labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            print('training -> epoch: %d, batch: %d, loss: %f' % (epoch, i_batch, loss.item()) + '\\r', end='')\n",
    "\n",
    "        print()\n",
    "        acc = correct / num_images\n",
    "        acc_test, test_loss = eval(net, test_loader)\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        training_losses.append(average_loss)\n",
    "        val_losses.append(test_loss)\n",
    "        print('\\nepoch: %d, lr: %f, accuracy: %f, avg. loss: %f, test accuracy: %f test loss: %f\\n' % (epoch, optimizer.param_groups[0]['lr'], acc, average_loss, acc_test, test_loss))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return net, training_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "Batch Size: 5\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 10\n",
      "Number of Workers: 4\n",
      "Number of Classes: 5\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Training Iteration: 0\n",
      "Using 20 images per class SeaLake\n",
      "Using 20 images per class Forest\n",
      "Using 20 images per class PermanentCrop\n",
      "Using 20 images per class HerbaceousVegetation\n",
      "Using 20 images per class Residential\n",
      "Class distribution summary in Training set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 25\n",
      "\n",
      "SeaLake: 5 samples (20.00%) | Forest: 5 samples (20.00%) | PermanentCrop: 5 samples (20.00%) | HerbaceousVegetation: 5 samples (20.00%) | \n",
      "Residential: 5 samples (20.00%) | \n",
      "\n",
      "Class distribution summary in Testing set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 75\n",
      "\n",
      "SeaLake: 15 samples (20.00%) | Forest: 15 samples (20.00%) | PermanentCrop: 15 samples (20.00%) | HerbaceousVegetation: 15 samples (20.00%) | \n",
      "Residential: 15 samples (20.00%) | \n",
      "\n",
      "training -> epoch: 0, batch: 4, loss: 1.622237\n",
      "testing -> batch: 14 correct: 21 num of images: 75\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.240000, avg. loss: 1.887893, test accuracy: 0.280000 test loss: 1.553758\n",
      "\n",
      "training -> epoch: 1, batch: 4, loss: 0.754644\n",
      "testing -> batch: 14 correct: 36 num of images: 75\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.600000, avg. loss: 0.853600, test accuracy: 0.480000 test loss: 1.216159\n",
      "\n",
      "training -> epoch: 2, batch: 4, loss: 1.762823\n",
      "testing -> batch: 14 correct: 41 num of images: 75\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.680000, avg. loss: 0.929336, test accuracy: 0.546667 test loss: 1.072426\n",
      "\n",
      "training -> epoch: 3, batch: 4, loss: 0.463287\n",
      "testing -> batch: 14 correct: 48 num of images: 75\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.720000, avg. loss: 0.818798, test accuracy: 0.640000 test loss: 0.952634\n",
      "\n",
      "training -> epoch: 4, batch: 4, loss: 0.490875\n",
      "testing -> batch: 14 correct: 54 num of images: 75\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.880000, avg. loss: 0.541705, test accuracy: 0.720000 test loss: 0.756744\n",
      "\n",
      "training -> epoch: 5, batch: 4, loss: 0.868606\n",
      "testing -> batch: 14 correct: 52 num of images: 75\n",
      "epoch: 5, lr: 0.000100, accuracy: 0.920000, avg. loss: 0.358430, test accuracy: 0.693333 test loss: 0.791652\n",
      "\n",
      "training -> epoch: 6, batch: 4, loss: 0.152646\n",
      "testing -> batch: 14 correct: 48 num of images: 75\n",
      "epoch: 6, lr: 0.000100, accuracy: 0.920000, avg. loss: 0.401061, test accuracy: 0.640000 test loss: 0.902720\n",
      "\n",
      "training -> epoch: 7, batch: 4, loss: 0.444267\n",
      "testing -> batch: 14 correct: 49 num of images: 75\n",
      "epoch: 7, lr: 0.000001, accuracy: 0.880000, avg. loss: 0.308531, test accuracy: 0.653333 test loss: 0.866352\n",
      "\n",
      "training -> epoch: 8, batch: 4, loss: 0.574040\n",
      "testing -> batch: 14 correct: 52 num of images: 75\n",
      "epoch: 8, lr: 0.000001, accuracy: 0.880000, avg. loss: 0.306046, test accuracy: 0.693333 test loss: 0.800019\n",
      "\n",
      "training -> epoch: 9, batch: 4, loss: 0.954203\n",
      "testing -> batch: 14 correct: 55 num of images: 75\n",
      "epoch: 9, lr: 0.000001, accuracy: 0.960000, avg. loss: 0.357596, test accuracy: 0.733333 test loss: 0.753072\n",
      "\n",
      "testing -> batch: 14 correct: 55 num of images: 75\n",
      "accuracy on testing data: 0.733333\n",
      "loss on testing data: 0.753072\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Training Iteration: 1\n",
      "Using 20 images per class AnnualCrop\n",
      "Using 20 images per class HerbaceousVegetation\n",
      "Using 20 images per class SeaLake\n",
      "Using 20 images per class Industrial\n",
      "Using 20 images per class Forest\n",
      "Class distribution summary in Training set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 25\n",
      "\n",
      "AnnualCrop: 5 samples (20.00%) | HerbaceousVegetation: 5 samples (20.00%) | SeaLake: 5 samples (20.00%) | Industrial: 5 samples (20.00%) | \n",
      "Forest: 5 samples (20.00%) | \n",
      "\n",
      "Class distribution summary in Testing set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 75\n",
      "\n",
      "AnnualCrop: 15 samples (20.00%) | HerbaceousVegetation: 15 samples (20.00%) | SeaLake: 15 samples (20.00%) | Industrial: 15 samples (20.00%) | \n",
      "Forest: 15 samples (20.00%) | \n",
      "\n",
      "training -> epoch: 0, batch: 4, loss: 2.342218\n",
      "testing -> batch: 14 correct: 26 num of images: 75\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.080000, avg. loss: 2.754496, test accuracy: 0.346667 test loss: 1.557176\n",
      "\n",
      "training -> epoch: 1, batch: 4, loss: 0.455926\n",
      "testing -> batch: 14 correct: 55 num of images: 75\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.560000, avg. loss: 1.083514, test accuracy: 0.733333 test loss: 0.730691\n",
      "\n",
      "training -> epoch: 2, batch: 4, loss: 0.350987\n",
      "testing -> batch: 14 correct: 62 num of images: 75\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.800000, avg. loss: 0.563734, test accuracy: 0.826667 test loss: 0.497362\n",
      "\n",
      "training -> epoch: 3, batch: 4, loss: 0.321437\n",
      "testing -> batch: 14 correct: 64 num of images: 75\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.720000, avg. loss: 0.803880, test accuracy: 0.853333 test loss: 0.465662\n",
      "\n",
      "training -> epoch: 4, batch: 4, loss: 0.965509\n",
      "testing -> batch: 14 correct: 64 num of images: 75\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.920000, avg. loss: 0.477647, test accuracy: 0.853333 test loss: 0.468245\n",
      "\n",
      "training -> epoch: 5, batch: 4, loss: 0.475560\n",
      "testing -> batch: 14 correct: 62 num of images: 75\n",
      "epoch: 5, lr: 0.000100, accuracy: 0.880000, avg. loss: 0.447732, test accuracy: 0.826667 test loss: 0.519886\n",
      "\n",
      "training -> epoch: 6, batch: 4, loss: 0.079525\n",
      "testing -> batch: 14 correct: 63 num of images: 75\n",
      "epoch: 6, lr: 0.000100, accuracy: 0.880000, avg. loss: 0.407475, test accuracy: 0.840000 test loss: 0.408999\n",
      "\n",
      "training -> epoch: 7, batch: 4, loss: 0.126003\n",
      "testing -> batch: 14 correct: 63 num of images: 75\n",
      "epoch: 7, lr: 0.000001, accuracy: 1.000000, avg. loss: 0.103908, test accuracy: 0.840000 test loss: 0.443797\n",
      "\n",
      "training -> epoch: 8, batch: 4, loss: 0.081014\n",
      "testing -> batch: 14 correct: 64 num of images: 75\n",
      "epoch: 8, lr: 0.000001, accuracy: 0.920000, avg. loss: 0.263818, test accuracy: 0.853333 test loss: 0.454228\n",
      "\n",
      "training -> epoch: 9, batch: 4, loss: 0.257388\n",
      "testing -> batch: 14 correct: 62 num of images: 75\n",
      "epoch: 9, lr: 0.000001, accuracy: 1.000000, avg. loss: 0.194323, test accuracy: 0.826667 test loss: 0.493795\n",
      "\n",
      "testing -> batch: 14 correct: 62 num of images: 75\n",
      "accuracy on testing data: 0.826667\n",
      "loss on testing data: 0.493795\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Training Iteration: 2\n",
      "Using 20 images per class River\n",
      "Using 20 images per class PermanentCrop\n",
      "Using 20 images per class SeaLake\n",
      "Using 20 images per class AnnualCrop\n",
      "Using 20 images per class Highway\n",
      "Class distribution summary in Training set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 25\n",
      "\n",
      "River: 5 samples (20.00%) | PermanentCrop: 5 samples (20.00%) | SeaLake: 5 samples (20.00%) | AnnualCrop: 5 samples (20.00%) | \n",
      "Highway: 5 samples (20.00%) | \n",
      "\n",
      "Class distribution summary in Testing set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 75\n",
      "\n",
      "River: 15 samples (20.00%) | PermanentCrop: 15 samples (20.00%) | SeaLake: 15 samples (20.00%) | AnnualCrop: 15 samples (20.00%) | \n",
      "Highway: 15 samples (20.00%) | \n",
      "\n",
      "training -> epoch: 0, batch: 4, loss: 1.453225\n",
      "testing -> batch: 14 correct: 32 num of images: 75\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.280000, avg. loss: 1.813024, test accuracy: 0.426667 test loss: 1.632604\n",
      "\n",
      "training -> epoch: 1, batch: 4, loss: 0.720213\n",
      "testing -> batch: 14 correct: 40 num of images: 75\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.760000, avg. loss: 0.637541, test accuracy: 0.533333 test loss: 1.266525\n",
      "\n",
      "training -> epoch: 2, batch: 4, loss: 0.147743\n",
      "testing -> batch: 14 correct: 42 num of images: 75\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.880000, avg. loss: 0.469906, test accuracy: 0.560000 test loss: 1.201689\n",
      "\n",
      "training -> epoch: 3, batch: 4, loss: 0.216711\n",
      "testing -> batch: 14 correct: 43 num of images: 75\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.880000, avg. loss: 0.295866, test accuracy: 0.573333 test loss: 1.289318\n",
      "\n",
      "training -> epoch: 4, batch: 4, loss: 0.230557\n",
      "testing -> batch: 14 correct: 44 num of images: 75\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.960000, avg. loss: 0.122810, test accuracy: 0.586667 test loss: 1.193796\n",
      "\n",
      "training -> epoch: 5, batch: 4, loss: 0.082034\n",
      "testing -> batch: 14 correct: 45 num of images: 75\n",
      "epoch: 5, lr: 0.000100, accuracy: 0.920000, avg. loss: 0.322354, test accuracy: 0.600000 test loss: 1.171996\n",
      "\n",
      "training -> epoch: 6, batch: 4, loss: 0.163842\n",
      "testing -> batch: 14 correct: 46 num of images: 75\n",
      "epoch: 6, lr: 0.000100, accuracy: 0.960000, avg. loss: 0.192097, test accuracy: 0.613333 test loss: 1.093457\n",
      "\n",
      "training -> epoch: 7, batch: 4, loss: 0.086657\n",
      "testing -> batch: 14 correct: 47 num of images: 75\n",
      "epoch: 7, lr: 0.000001, accuracy: 0.880000, avg. loss: 0.263261, test accuracy: 0.626667 test loss: 1.097051\n",
      "\n",
      "training -> epoch: 8, batch: 4, loss: 0.084223\n",
      "testing -> batch: 14 correct: 47 num of images: 75\n",
      "epoch: 8, lr: 0.000001, accuracy: 1.000000, avg. loss: 0.098732, test accuracy: 0.626667 test loss: 1.081628\n",
      "\n",
      "training -> epoch: 9, batch: 4, loss: 0.249091\n",
      "testing -> batch: 14 correct: 48 num of images: 75\n",
      "epoch: 9, lr: 0.000001, accuracy: 1.000000, avg. loss: 0.092271, test accuracy: 0.640000 test loss: 1.064682\n",
      "\n",
      "testing -> batch: 14 correct: 48 num of images: 75\n",
      "accuracy on testing data: 0.640000\n",
      "loss on testing data: 1.064682\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Training Iteration: 3\n",
      "Using 20 images per class Pasture\n",
      "Using 20 images per class Highway\n",
      "Using 20 images per class PermanentCrop\n",
      "Using 20 images per class HerbaceousVegetation\n",
      "Using 20 images per class Residential\n",
      "Class distribution summary in Training set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 25\n",
      "\n",
      "Pasture: 5 samples (20.00%) | Highway: 5 samples (20.00%) | PermanentCrop: 5 samples (20.00%) | HerbaceousVegetation: 5 samples (20.00%) | \n",
      "Residential: 5 samples (20.00%) | \n",
      "\n",
      "Class distribution summary in Testing set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 75\n",
      "\n",
      "Pasture: 15 samples (20.00%) | Highway: 15 samples (20.00%) | PermanentCrop: 15 samples (20.00%) | HerbaceousVegetation: 15 samples (20.00%) | \n",
      "Residential: 15 samples (20.00%) | \n",
      "\n",
      "training -> epoch: 0, batch: 4, loss: 2.157829\n",
      "testing -> batch: 14 correct: 20 num of images: 75\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.240000, avg. loss: 1.978429, test accuracy: 0.266667 test loss: 2.304911\n",
      "\n",
      "training -> epoch: 1, batch: 4, loss: 0.901906\n",
      "testing -> batch: 14 correct: 28 num of images: 75\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.520000, avg. loss: 1.063742, test accuracy: 0.373333 test loss: 1.863154\n",
      "\n",
      "training -> epoch: 2, batch: 4, loss: 0.148156\n",
      "testing -> batch: 14 correct: 34 num of images: 75\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.760000, avg. loss: 0.630572, test accuracy: 0.453333 test loss: 1.555875\n",
      "\n",
      "training -> epoch: 3, batch: 4, loss: 0.735786\n",
      "testing -> batch: 14 correct: 37 num of images: 75\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.760000, avg. loss: 0.559695, test accuracy: 0.493333 test loss: 1.361600\n",
      "\n",
      "training -> epoch: 4, batch: 4, loss: 0.320543\n",
      "testing -> batch: 14 correct: 41 num of images: 75\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.840000, avg. loss: 0.343477, test accuracy: 0.546667 test loss: 1.259018\n",
      "\n",
      "training -> epoch: 5, batch: 4, loss: 0.602821\n",
      "testing -> batch: 14 correct: 38 num of images: 75\n",
      "epoch: 5, lr: 0.000100, accuracy: 0.800000, avg. loss: 0.438729, test accuracy: 0.506667 test loss: 1.314547\n",
      "\n",
      "training -> epoch: 6, batch: 4, loss: 0.113950\n",
      "testing -> batch: 14 correct: 40 num of images: 75\n",
      "epoch: 6, lr: 0.000100, accuracy: 1.000000, avg. loss: 0.115902, test accuracy: 0.533333 test loss: 1.311118\n",
      "\n",
      "training -> epoch: 7, batch: 4, loss: 0.258634\n",
      "testing -> batch: 14 correct: 41 num of images: 75\n",
      "epoch: 7, lr: 0.000001, accuracy: 0.840000, avg. loss: 0.349273, test accuracy: 0.546667 test loss: 1.285070\n",
      "\n",
      "training -> epoch: 8, batch: 4, loss: 0.044662\n",
      "testing -> batch: 14 correct: 42 num of images: 75\n",
      "epoch: 8, lr: 0.000001, accuracy: 0.960000, avg. loss: 0.214346, test accuracy: 0.560000 test loss: 1.282329\n",
      "\n",
      "training -> epoch: 9, batch: 4, loss: 0.080391\n",
      "testing -> batch: 14 correct: 42 num of images: 75\n",
      "epoch: 9, lr: 0.000001, accuracy: 1.000000, avg. loss: 0.091127, test accuracy: 0.560000 test loss: 1.264653\n",
      "\n",
      "testing -> batch: 14 correct: 42 num of images: 75\n",
      "accuracy on testing data: 0.560000\n",
      "loss on testing data: 1.264653\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Training Iteration: 4\n",
      "Using 20 images per class PermanentCrop\n",
      "Using 20 images per class Residential\n",
      "Using 20 images per class River\n",
      "Using 20 images per class Pasture\n",
      "Using 20 images per class Forest\n",
      "Class distribution summary in Training set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 25\n",
      "\n",
      "PermanentCrop: 5 samples (20.00%) | Residential: 5 samples (20.00%) | River: 5 samples (20.00%) | Pasture: 5 samples (20.00%) | \n",
      "Forest: 5 samples (20.00%) | \n",
      "\n",
      "Class distribution summary in Testing set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 75\n",
      "\n",
      "PermanentCrop: 15 samples (20.00%) | Residential: 15 samples (20.00%) | River: 15 samples (20.00%) | Pasture: 15 samples (20.00%) | \n",
      "Forest: 15 samples (20.00%) | \n",
      "\n",
      "training -> epoch: 0, batch: 4, loss: 1.547736\n",
      "testing -> batch: 14 correct: 18 num of images: 75\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.240000, avg. loss: 2.763751, test accuracy: 0.240000 test loss: 2.249183\n",
      "\n",
      "training -> epoch: 1, batch: 4, loss: 0.972070\n",
      "testing -> batch: 14 correct: 34 num of images: 75\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.520000, avg. loss: 1.079505, test accuracy: 0.453333 test loss: 1.558108\n",
      "\n",
      "training -> epoch: 2, batch: 4, loss: 0.617603\n",
      "testing -> batch: 14 correct: 41 num of images: 75\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.760000, avg. loss: 0.613642, test accuracy: 0.546667 test loss: 1.322799\n",
      "\n",
      "training -> epoch: 3, batch: 4, loss: 0.601471\n",
      "testing -> batch: 14 correct: 41 num of images: 75\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.960000, avg. loss: 0.311511, test accuracy: 0.546667 test loss: 1.173856\n",
      "\n",
      "training -> epoch: 4, batch: 4, loss: 0.330957\n",
      "testing -> batch: 14 correct: 48 num of images: 75\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.960000, avg. loss: 0.229153, test accuracy: 0.640000 test loss: 1.141250\n",
      "\n",
      "training -> epoch: 5, batch: 4, loss: 0.097246\n",
      "testing -> batch: 14 correct: 49 num of images: 75\n",
      "epoch: 5, lr: 0.000100, accuracy: 1.000000, avg. loss: 0.099770, test accuracy: 0.653333 test loss: 1.053925\n",
      "\n",
      "training -> epoch: 6, batch: 4, loss: 0.100748\n",
      "testing -> batch: 14 correct: 51 num of images: 75\n",
      "epoch: 6, lr: 0.000100, accuracy: 0.920000, avg. loss: 0.313958, test accuracy: 0.680000 test loss: 0.944570\n",
      "\n",
      "training -> epoch: 7, batch: 4, loss: 0.281340\n",
      "testing -> batch: 14 correct: 49 num of images: 75\n",
      "epoch: 7, lr: 0.000001, accuracy: 0.840000, avg. loss: 0.352159, test accuracy: 0.653333 test loss: 0.992502\n",
      "\n",
      "training -> epoch: 8, batch: 4, loss: 0.257205\n",
      "testing -> batch: 14 correct: 50 num of images: 75\n",
      "epoch: 8, lr: 0.000001, accuracy: 0.960000, avg. loss: 0.144095, test accuracy: 0.666667 test loss: 0.981326\n",
      "\n",
      "training -> epoch: 9, batch: 4, loss: 0.023255\n",
      "testing -> batch: 14 correct: 50 num of images: 75\n",
      "epoch: 9, lr: 0.000001, accuracy: 1.000000, avg. loss: 0.052373, test accuracy: 0.666667 test loss: 1.011717\n",
      "\n",
      "testing -> batch: 14 correct: 50 num of images: 75\n",
      "accuracy on testing data: 0.666667\n",
      "loss on testing data: 1.011717\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Training Iteration: 5\n",
      "Using 20 images per class Highway\n",
      "Using 20 images per class HerbaceousVegetation\n",
      "Using 20 images per class Residential\n",
      "Using 20 images per class River\n",
      "Using 20 images per class Industrial\n",
      "Class distribution summary in Training set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 25\n",
      "\n",
      "Highway: 5 samples (20.00%) | HerbaceousVegetation: 5 samples (20.00%) | Residential: 5 samples (20.00%) | River: 5 samples (20.00%) | \n",
      "Industrial: 5 samples (20.00%) | \n",
      "\n",
      "Class distribution summary in Testing set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 75\n",
      "\n",
      "Highway: 15 samples (20.00%) | HerbaceousVegetation: 15 samples (20.00%) | Residential: 15 samples (20.00%) | River: 15 samples (20.00%) | \n",
      "Industrial: 15 samples (20.00%) | \n",
      "\n",
      "training -> epoch: 0, batch: 4, loss: 3.692341\n",
      "testing -> batch: 14 correct: 19 num of images: 75\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.080000, avg. loss: 3.197129, test accuracy: 0.253333 test loss: 2.317612\n",
      "\n",
      "training -> epoch: 1, batch: 4, loss: 0.599639\n",
      "testing -> batch: 14 correct: 38 num of images: 75\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.600000, avg. loss: 1.049163, test accuracy: 0.506667 test loss: 1.304859\n",
      "\n",
      "training -> epoch: 2, batch: 4, loss: 0.569725\n",
      "testing -> batch: 14 correct: 47 num of images: 75\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.760000, avg. loss: 0.620643, test accuracy: 0.626667 test loss: 1.010109\n",
      "\n",
      "training -> epoch: 3, batch: 4, loss: 0.930814\n",
      "testing -> batch: 14 correct: 49 num of images: 75\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.720000, avg. loss: 0.589386, test accuracy: 0.653333 test loss: 0.928808\n",
      "\n",
      "training -> epoch: 4, batch: 4, loss: 0.207029\n",
      "testing -> batch: 14 correct: 51 num of images: 75\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.880000, avg. loss: 0.285690, test accuracy: 0.680000 test loss: 0.865069\n",
      "\n",
      "training -> epoch: 5, batch: 4, loss: 0.091578\n",
      "testing -> batch: 14 correct: 50 num of images: 75\n",
      "epoch: 5, lr: 0.000100, accuracy: 0.920000, avg. loss: 0.198441, test accuracy: 0.666667 test loss: 0.862676\n",
      "\n",
      "training -> epoch: 6, batch: 4, loss: 0.186752\n",
      "testing -> batch: 14 correct: 54 num of images: 75\n",
      "epoch: 6, lr: 0.000100, accuracy: 1.000000, avg. loss: 0.118897, test accuracy: 0.720000 test loss: 0.801983\n",
      "\n",
      "training -> epoch: 7, batch: 4, loss: 0.198574\n",
      "testing -> batch: 14 correct: 55 num of images: 75\n",
      "epoch: 7, lr: 0.000001, accuracy: 0.960000, avg. loss: 0.217553, test accuracy: 0.733333 test loss: 0.786281\n",
      "\n",
      "training -> epoch: 8, batch: 4, loss: 0.033366\n",
      "testing -> batch: 14 correct: 56 num of images: 75\n",
      "epoch: 8, lr: 0.000001, accuracy: 1.000000, avg. loss: 0.174143, test accuracy: 0.746667 test loss: 0.770246\n",
      "\n",
      "training -> epoch: 9, batch: 4, loss: 0.079889\n",
      "testing -> batch: 14 correct: 54 num of images: 75\n",
      "epoch: 9, lr: 0.000001, accuracy: 0.840000, avg. loss: 0.322937, test accuracy: 0.720000 test loss: 0.817391\n",
      "\n",
      "testing -> batch: 14 correct: 54 num of images: 75\n",
      "accuracy on testing data: 0.720000\n",
      "loss on testing data: 0.817391\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Training Iteration: 6\n",
      "Using 20 images per class PermanentCrop\n",
      "Using 20 images per class River\n",
      "Using 20 images per class Residential\n",
      "Using 20 images per class Industrial\n",
      "Using 20 images per class Highway\n",
      "Class distribution summary in Training set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 25\n",
      "\n",
      "PermanentCrop: 5 samples (20.00%) | River: 5 samples (20.00%) | Residential: 5 samples (20.00%) | Industrial: 5 samples (20.00%) | \n",
      "Highway: 5 samples (20.00%) | \n",
      "\n",
      "Class distribution summary in Testing set:\n",
      "Number of Classes: 5\n",
      "Total Samples: 75\n",
      "\n",
      "PermanentCrop: 15 samples (20.00%) | River: 15 samples (20.00%) | Residential: 15 samples (20.00%) | Industrial: 15 samples (20.00%) | \n",
      "Highway: 15 samples (20.00%) | \n",
      "\n",
      "training -> epoch: 0, batch: 4, loss: 2.638217\n",
      "testing -> batch: 14 correct: 33 num of images: 75\n",
      "epoch: 0, lr: 0.000100, accuracy: 0.320000, avg. loss: 2.405824, test accuracy: 0.440000 test loss: 1.797754\n",
      "\n",
      "training -> epoch: 1, batch: 4, loss: 1.348439\n",
      "testing -> batch: 14 correct: 38 num of images: 75\n",
      "epoch: 1, lr: 0.000100, accuracy: 0.440000, avg. loss: 1.419907, test accuracy: 0.506667 test loss: 1.316413\n",
      "\n",
      "training -> epoch: 2, batch: 4, loss: 0.332716\n",
      "testing -> batch: 14 correct: 45 num of images: 75\n",
      "epoch: 2, lr: 0.000100, accuracy: 0.840000, avg. loss: 0.523913, test accuracy: 0.600000 test loss: 1.089710\n",
      "\n",
      "training -> epoch: 3, batch: 4, loss: 0.205545\n",
      "testing -> batch: 14 correct: 47 num of images: 75\n",
      "epoch: 3, lr: 0.000100, accuracy: 0.840000, avg. loss: 0.451017, test accuracy: 0.626667 test loss: 0.932138\n",
      "\n",
      "training -> epoch: 4, batch: 4, loss: 0.105109\n",
      "testing -> batch: 14 correct: 50 num of images: 75\n",
      "epoch: 4, lr: 0.000100, accuracy: 0.920000, avg. loss: 0.186666, test accuracy: 0.666667 test loss: 0.935167\n",
      "\n",
      "training -> epoch: 5, batch: 4, loss: 0.080784\n",
      "testing -> batch: 14 correct: 54 num of images: 75\n",
      "epoch: 5, lr: 0.000100, accuracy: 1.000000, avg. loss: 0.116201, test accuracy: 0.720000 test loss: 0.826778\n",
      "\n",
      "training -> epoch: 6, batch: 4, loss: 0.064015\n",
      "testing -> batch: 14 correct: 53 num of images: 75\n",
      "epoch: 6, lr: 0.000100, accuracy: 1.000000, avg. loss: 0.087240, test accuracy: 0.706667 test loss: 0.805273\n",
      "\n",
      "training -> epoch: 7, batch: 4, loss: 0.273180\n",
      "testing -> batch: 14 correct: 52 num of images: 75\n",
      "epoch: 7, lr: 0.000001, accuracy: 0.960000, avg. loss: 0.155154, test accuracy: 0.693333 test loss: 0.813275\n",
      "\n",
      "training -> epoch: 8, batch: 4, loss: 0.126142\n",
      "testing -> batch: 14 correct: 53 num of images: 75\n",
      "epoch: 8, lr: 0.000001, accuracy: 0.920000, avg. loss: 0.252456, test accuracy: 0.706667 test loss: 0.841828\n",
      "\n",
      "training -> epoch: 9, batch: 4, loss: 0.154656\r"
     ]
    }
   ],
   "source": [
    "from models.resnet18 import ResNet18\n",
    "\n",
    "batch_size = 5\n",
    "num_workers = 4\n",
    "learning_rate = 0.0001 # 0.00005 - the best one so far\n",
    "num_epochs = 5\n",
    "num_classes = 5\n",
    "\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Number of Workers: {num_workers}\")\n",
    "print(f\"Number of Classes: {num_classes}\\n\")\n",
    "\n",
    "##change this\n",
    "loaded_model = torch.load(os.path.join(os.getcwd(), 'pretrained/resnet18_model_77.pth'))\n",
    "model = ResNet18(num_classes=50).to(device)\n",
    "\n",
    "# Load the state dictionary into your model\n",
    "model.load_state_dict(loaded_model.state_dict())\n",
    "    \n",
    "in_features = model.resnet18.fc.in_features\n",
    "model.resnet18.fc = nn.Linear(in_features, num_classes).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for iter in range(8):\n",
    "    print('--------------------------------------------------------------')\n",
    "    print(f\"Training Iteration: {iter}\")\n",
    "    train_loader, test_loader = make_dataset_loaders(num_classes=num_classes, batch_size=batch_size, num_workers=num_workers)\n",
    "    model, training_losses, val_losses = train(net=model, train_loader=train_loader, test_loader=test_loader, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n",
    "    acc_test, test_loss = eval(model, test_loader)\n",
    "    print('\\naccuracy on testing data: %f' % acc_test)\n",
    "    print('loss on testing data: %f' % test_loss)\n",
    "    print('--------------------------------------------------------------')\n",
    "    \n",
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(test_loss, label='Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, os.path.join(os.getcwd(), 'trained/resnet18_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
