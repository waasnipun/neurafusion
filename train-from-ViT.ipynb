{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb51636c35ff179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.066661Z",
     "start_time": "2023-12-08T20:49:30.193666Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import Dataset\n",
    "from tools import getDataset, print_class_distribution\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c1117e99dc7cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.131235Z",
     "start_time": "2023-12-08T20:49:31.127636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9bdb650d1ebe5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.684904Z",
     "start_time": "2023-12-08T20:49:31.553813Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_dataset_loaders(num_classes, batch_size, num_workers, image_size):\n",
    "    root_dir = os.path.join(os.getcwd(), 'datasets/EuroSAT_RGB')\n",
    "    dataset, label_mapping = getDataset(path=root_dir, num_classes=num_classes, num_images_per_class=20, shuffle_images=False)\n",
    "\n",
    "    class_images = {i: [] for i in range(num_classes)}\n",
    "\n",
    "    # Group images by class\n",
    "    for image_path, class_label in dataset:\n",
    "        class_images[class_label].append((image_path, class_label))\n",
    "\n",
    "    # Initialize training and test sets\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "\n",
    "    # Select 5 images for training and 15 for testing from each class\n",
    "    for class_label, images in class_images.items():\n",
    "        train_set.extend(random.sample(images, k=5))\n",
    "        test_set.extend(list(set(images) - set(train_set)))\n",
    "\n",
    "\n",
    "    train_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.RandomCrop(image_size, padding=8),\n",
    "                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "                transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(degrees=5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    test_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    train_dataset = Dataset(dataset=train_set, path=root_dir, phase='train', transform=train_transforms)\n",
    "    test_dataset = Dataset(dataset=test_set, path=root_dir, phase='test', transform=test_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    print_class_distribution(train_dataset, \"Training\", label_mapping)\n",
    "    print_class_distribution(test_dataset, \"Testing\", label_mapping)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfab17de52b40940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:49:31.696316Z",
     "start_time": "2023-12-08T20:49:31.691779Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval(net, data_loader, criterion=nn.CrossEntropyLoss()):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "    net.eval()\n",
    "    correct = 0.0\n",
    "    num_images = 0.0\n",
    "    loss = 0.0\n",
    "    for i_batch, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outs = net(images)\n",
    "        loss += criterion(outs, labels).item()\n",
    "        _, predicted = torch.max(outs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        num_images += len(labels)\n",
    "        print('testing -> batch: %d correct: %d num of images: %d' % (i_batch, correct, num_images) + '\\r', end='')\n",
    "    acc = correct / num_images\n",
    "    loss /= len(data_loader)\n",
    "    return acc, loss\n",
    "\n",
    "\n",
    "# training function\n",
    "def train(net, train_loader, test_loader, num_epochs, learning_rate):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(params= net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.0001, betas=(0.5, 0.999))\n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.01)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    training_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        correct = 0.0  # used to accumulate number of correctly recognized images\n",
    "        num_images = 0.0  # used to accumulate number of images\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i_batch, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output_train = net(images)\n",
    "            loss = criterion(output_train, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicts = output_train.argmax(dim=1)\n",
    "            correct += predicts.eq(labels).sum().item()\n",
    "            num_images += len(labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            print('training -> epoch: %d, batch: %d, loss: %f' % (epoch, i_batch, loss.item()) + '\\r', end='')\n",
    "\n",
    "        print()\n",
    "        acc = correct / num_images\n",
    "        acc_test, test_loss = eval(net, test_loader)\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        training_losses.append(average_loss)\n",
    "        val_losses.append(test_loss)\n",
    "        print('\\nepoch: %d, lr: %f, accuracy: %f, avg. loss: %f, test accuracy: %f test loss: %f\\n' % (epoch, optimizer.param_groups[0]['lr'], acc, average_loss, acc_test, test_loss))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return net, training_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5946d8482020b135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T20:50:42.603195Z",
     "start_time": "2023-12-08T20:49:40.896904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "Batch Size: 5\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 3\n",
      "Number of Workers: 4\n",
      "Number of Classes: 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/vit_small_p16_224-15ec54c9.pth\" to /Users/nipunwaas/.cache/torch/hub/checkpoints/vit_small_p16_224-15ec54c9.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ViT:\n\tUnexpected key(s) in state_dict: \"vit.blocks.8.norm1.weight\", \"vit.blocks.8.norm1.bias\", \"vit.blocks.8.attn.qkv.weight\", \"vit.blocks.8.attn.qkv.bias\", \"vit.blocks.8.attn.proj.weight\", \"vit.blocks.8.attn.proj.bias\", \"vit.blocks.8.norm2.weight\", \"vit.blocks.8.norm2.bias\", \"vit.blocks.8.mlp.fc1.weight\", \"vit.blocks.8.mlp.fc1.bias\", \"vit.blocks.8.mlp.fc2.weight\", \"vit.blocks.8.mlp.fc2.bias\", \"vit.blocks.9.norm1.weight\", \"vit.blocks.9.norm1.bias\", \"vit.blocks.9.attn.qkv.weight\", \"vit.blocks.9.attn.qkv.bias\", \"vit.blocks.9.attn.proj.weight\", \"vit.blocks.9.attn.proj.bias\", \"vit.blocks.9.norm2.weight\", \"vit.blocks.9.norm2.bias\", \"vit.blocks.9.mlp.fc1.weight\", \"vit.blocks.9.mlp.fc1.bias\", \"vit.blocks.9.mlp.fc2.weight\", \"vit.blocks.9.mlp.fc2.bias\", \"vit.blocks.10.norm1.weight\", \"vit.blocks.10.norm1.bias\", \"vit.blocks.10.attn.qkv.weight\", \"vit.blocks.10.attn.qkv.bias\", \"vit.blocks.10.attn.proj.weight\", \"vit.blocks.10.attn.proj.bias\", \"vit.blocks.10.norm2.weight\", \"vit.blocks.10.norm2.bias\", \"vit.blocks.10.mlp.fc1.weight\", \"vit.blocks.10.mlp.fc1.bias\", \"vit.blocks.10.mlp.fc2.weight\", \"vit.blocks.10.mlp.fc2.bias\", \"vit.blocks.11.norm1.weight\", \"vit.blocks.11.norm1.bias\", \"vit.blocks.11.attn.qkv.weight\", \"vit.blocks.11.attn.qkv.bias\", \"vit.blocks.11.attn.proj.weight\", \"vit.blocks.11.attn.proj.bias\", \"vit.blocks.11.norm2.weight\", \"vit.blocks.11.norm2.bias\", \"vit.blocks.11.mlp.fc1.weight\", \"vit.blocks.11.mlp.fc1.bias\", \"vit.blocks.11.mlp.fc2.weight\", \"vit.blocks.11.mlp.fc2.bias\", \"vit.blocks.0.attn.qkv.bias\", \"vit.blocks.1.attn.qkv.bias\", \"vit.blocks.2.attn.qkv.bias\", \"vit.blocks.3.attn.qkv.bias\", \"vit.blocks.4.attn.qkv.bias\", \"vit.blocks.5.attn.qkv.bias\", \"vit.blocks.6.attn.qkv.bias\", \"vit.blocks.7.attn.qkv.bias\". \n\tsize mismatch for vit.cls_token: copying a param with shape torch.Size([1, 1, 384]) from checkpoint, the shape in current model is torch.Size([1, 1, 768]).\n\tsize mismatch for vit.pos_embed: copying a param with shape torch.Size([1, 197, 384]) from checkpoint, the shape in current model is torch.Size([1, 197, 768]).\n\tsize mismatch for vit.patch_embed.proj.weight: copying a param with shape torch.Size([384, 3, 16, 16]) from checkpoint, the shape in current model is torch.Size([768, 3, 16, 16]).\n\tsize mismatch for vit.patch_embed.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.0.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.0.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.1.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.1.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.2.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.2.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.3.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.3.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.4.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.4.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.5.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.5.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.6.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.6.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.6.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.6.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.6.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.7.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.7.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.7.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.7.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.7.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.head.weight: copying a param with shape torch.Size([50, 384]) from checkpoint, the shape in current model is torch.Size([50, 768]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q_/vt2y0l_534b26099_6gg5hl40000gn/T/ipykernel_15878/2762582265.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Load the state dictionary into your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2153\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ViT:\n\tUnexpected key(s) in state_dict: \"vit.blocks.8.norm1.weight\", \"vit.blocks.8.norm1.bias\", \"vit.blocks.8.attn.qkv.weight\", \"vit.blocks.8.attn.qkv.bias\", \"vit.blocks.8.attn.proj.weight\", \"vit.blocks.8.attn.proj.bias\", \"vit.blocks.8.norm2.weight\", \"vit.blocks.8.norm2.bias\", \"vit.blocks.8.mlp.fc1.weight\", \"vit.blocks.8.mlp.fc1.bias\", \"vit.blocks.8.mlp.fc2.weight\", \"vit.blocks.8.mlp.fc2.bias\", \"vit.blocks.9.norm1.weight\", \"vit.blocks.9.norm1.bias\", \"vit.blocks.9.attn.qkv.weight\", \"vit.blocks.9.attn.qkv.bias\", \"vit.blocks.9.attn.proj.weight\", \"vit.blocks.9.attn.proj.bias\", \"vit.blocks.9.norm2.weight\", \"vit.blocks.9.norm2.bias\", \"vit.blocks.9.mlp.fc1.weight\", \"vit.blocks.9.mlp.fc1.bias\", \"vit.blocks.9.mlp.fc2.weight\", \"vit.blocks.9.mlp.fc2.bias\", \"vit.blocks.10.norm1.weight\", \"vit.blocks.10.norm1.bias\", \"vit.blocks.10.attn.qkv.weight\", \"vit.blocks.10.attn.qkv.bias\", \"vit.blocks.10.attn.proj.weight\", \"vit.blocks.10.attn.proj.bias\", \"vit.blocks.10.norm2.weight\", \"vit.blocks.10.norm2.bias\", \"vit.blocks.10.mlp.fc1.weight\", \"vit.blocks.10.mlp.fc1.bias\", \"vit.blocks.10.mlp.fc2.weight\", \"vit.blocks.10.mlp.fc2.bias\", \"vit.blocks.11.norm1.weight\", \"vit.blocks.11.norm1.bias\", \"vit.blocks.11.attn.qkv.weight\", \"vit.blocks.11.attn.qkv.bias\", \"vit.blocks.11.attn.proj.weight\", \"vit.blocks.11.attn.proj.bias\", \"vit.blocks.11.norm2.weight\", \"vit.blocks.11.norm2.bias\", \"vit.blocks.11.mlp.fc1.weight\", \"vit.blocks.11.mlp.fc1.bias\", \"vit.blocks.11.mlp.fc2.weight\", \"vit.blocks.11.mlp.fc2.bias\", \"vit.blocks.0.attn.qkv.bias\", \"vit.blocks.1.attn.qkv.bias\", \"vit.blocks.2.attn.qkv.bias\", \"vit.blocks.3.attn.qkv.bias\", \"vit.blocks.4.attn.qkv.bias\", \"vit.blocks.5.attn.qkv.bias\", \"vit.blocks.6.attn.qkv.bias\", \"vit.blocks.7.attn.qkv.bias\". \n\tsize mismatch for vit.cls_token: copying a param with shape torch.Size([1, 1, 384]) from checkpoint, the shape in current model is torch.Size([1, 1, 768]).\n\tsize mismatch for vit.pos_embed: copying a param with shape torch.Size([1, 197, 384]) from checkpoint, the shape in current model is torch.Size([1, 197, 768]).\n\tsize mismatch for vit.patch_embed.proj.weight: copying a param with shape torch.Size([384, 3, 16, 16]) from checkpoint, the shape in current model is torch.Size([768, 3, 16, 16]).\n\tsize mismatch for vit.patch_embed.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.0.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.0.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.1.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.1.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.2.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.2.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.3.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.3.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.4.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.4.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.5.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.5.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.6.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.6.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.6.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.6.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.6.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.6.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.7.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for vit.blocks.7.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.blocks.7.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for vit.blocks.7.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for vit.blocks.7.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 2304]).\n\tsize mismatch for vit.blocks.7.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for vit.head.weight: copying a param with shape torch.Size([50, 384]) from checkpoint, the shape in current model is torch.Size([50, 768])."
     ]
    }
   ],
   "source": [
    "from models.ViT import ViT\n",
    "\n",
    "batch_size = 5\n",
    "num_workers = 4\n",
    "learning_rate = 0.0001 # 0.00005 - the best one so far\n",
    "num_epochs = 3\n",
    "num_classes = 5\n",
    "image_size = 224\n",
    "\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Number of Workers: {num_workers}\")\n",
    "print(f\"Number of Classes: {num_classes}\\n\")\n",
    "\n",
    "\n",
    "loaded_model = torch.load(os.path.join(os.getcwd(), 'pretrained/vit_model_best_90.pth'), map_location=device)\n",
    "model = ViT(num_classes=50).to(device)\n",
    "\n",
    "# Load the state dictionary into your model\n",
    "model.load_state_dict(loaded_model.state_dict())\n",
    "\n",
    "in_features = model.vit.head.in_features\n",
    "model.vit.head = nn.Linear(in_features, num_classes).to(device)  \n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for iter in range(4):\n",
    "    print('--------------------------------------------------------------')\n",
    "    print(f\"Training Iteration: {iter}\")\n",
    "    train_loader, test_loader = make_dataset_loaders(num_classes=num_classes, batch_size=batch_size, num_workers=num_workers, image_size=image_size)\n",
    "    model, training_losses, val_losses = train(net=model, train_loader=train_loader, test_loader=test_loader, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n",
    "    acc_test, test_loss = eval(model, test_loader)\n",
    "    print('\\naccuracy on testing data: %f' % acc_test)\n",
    "    print('loss on testing data: %f' % test_loss)\n",
    "    print('--------------------------------------------------------------')\n",
    "    \n",
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(test_loss, label='Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  \n",
    "\n",
    "for i_batch, (images, labels) in enumerate(test_loader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outs = model(images)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    print(predicted)\n",
    "    print(labels)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    print(correct, len(labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea4a865692f9c48",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T16:10:09.511634Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "torch.save(model, os.path.join(os.getcwd(), 'pretrained/vit_trained.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b04fba26407c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
